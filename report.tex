\include{preamble}

\newtotcounter{citenum} %From the package documentation
\def\oldbibitem{}
\let\oldbibitem=\bibitem
\def\bibitem{\stepcounter{citenum}\oldbibitem}

\begin{document}
\includepdf[pages={1}]
{title.pdf}

\tableofcontents
\newpage

\section{Введение}
Один из наиболее распространенных движущих факторов прогресса – искусственный
интеллект (далее – ИИ). ИИ следует рассматривать как программу, которая, благодаря
итеративному обучению на больших массивах данных, способна создавать независимые от
замысла разработчиков результаты.

Крайне широкий спектр применения искусственного интеллекта требует принятия
своевременных и эффективных мер по совершенствованию правового регулирования по
обширному кругу вопросов. Наиболее актуальные темы включают вопросы безопасности,
ответственности, использования и защиты данных, интеллектуальной собственности.

Цель данной работы -- обозначить некоторые правовые проблемы, возникающие при использовании ИИ,
ответственность, связанную с рисками применения самообучающихся алгоритмов для
решения различных задач, и привести примеры, иллюстрирующие эти задачи в реальной жизни.

\newpage
\section{Правосубъектность искусственного интеллекта}
Одной из главных мировых проблем является правосубъектность ИИ. Ключевые вопросы, связанные
с этой темой, изложены в статье \cite{II}. Её автор дает ответ на некоторые из них.
В частности, по теме авторства и права собственности он выделяет следующие тезисы:

\begin{enumerate}
\item На оригинальные литературные и художественные произведения, которые создаются ИИ в автономном режиме,
следует распространить режим авторско-правовой охраны.
\item Права авторства следует предоставить человеку (коллективу) – разработчику ИИ с фиксацией последнего как
субъекта или инструмента субъекта права.
\item Возможно, следует ввести определенные ограничения правовой охраны для оригинальных литературных и
художественных произведений.
\end{enumerate}

Что касается несанкционированного использования для машинного обучения данных, которые относятся к произведениям, являющимися
объектами авторско-правовой охраны, то автор статьи \cite{II} отмечает, что его не следует считать нарушением
авторского права. При этом в системе авторского права или в других профильных нормативно-правовых актах
следует предусмотреть конкретное исключение в отношении использования таких данных для обучения ИИ-программ.

В дополнение к идее статьи \cite{II}, в работе \cite{chel} утверждается, что
проявление творческого потенциала ИИ не обеспечивает его включение как субъекта в рамки
права интеллектуальной собственности, основополагающие концепции которого в качестве автора,
способного к творческой деятельности, рассматривают исключительно физическое лицо. В статье
\cite{chel} данный вопрос, при взятых во внимание некоторых международных конференциях,
признается дискуссионным. Но в качестве наиболее вероятных решений проблемы приняты следующие положения:

\begin{enumerate}
\item Отказ от рассмотрения ИИ в качестве самостоятельного субъекта права интеллектуальной собственности.
\item Проведение разграничения результатов деятельности ИИ по критерию степени участия человека и
использования ИИ, а также установление различных правовых режимов для случаев, где ИИ играет
инструментальную роль, и случаев, где ИИ выступает с определенной степенью автономности.
\item Включение в национальное законодательство нормы о возможности использования законно
доступных объектов интеллектуальной собственности для целей обучения систем ИИ, если
правообладателем не выражено явное возражение против этого в надлежащей форме.
\end{enumerate}

В статье \cite{probs} автор придерживается аналогичного мнения. Он считает
обоснованным подход, в котором автором и правообладателем, соответственно,
будет признаваться владелец (собственник) робота. Но тогда неминуемо встаёт вопрос о том,
а каков будет правовой статус искусственного интеллекта после смерти его владельца?
Кто будет нести ответственность за все то, что успеет совершить ИИ?

Автор считает, что
искусственный интеллект не может нести ответственность сам по себе, поскольку его действия
или бездействия зависят от оператора (владельца), следовательно, он и
должен быть ответственным. Но этот вопрос открыт для обсуждения, и в
случае сильно развитого ИИ, законодатель обязан пересмотреть пределы ответственности
как самого интеллекта, так и его оператора или создателя.

Однако существует и несколько иной вариант решения проблемы правосубъектности ИИ. В работе
\cite{mor} автор предлагает следующую альтернативу: наделение системы искусственного интеллекта
правовым статусом социального агента, не имеющего собственных прав; таким образом, все произведения,
создаваемые с участием такой системы, переходят в общественное достояние.

Если развить эту идею, то
нет насущной необходимости кардинально менять всю систему и принципы данной отрасли права для того,
чтобы обеспечить признание правосубъектности систем искусственного интеллекта. Тем временем, машины
не будут настолько обособлены от людей, как это предполагается в статьях \cite{chel} и \cite{probs}.

\newpage

\section{Проблема патентной охраны}
Согласно \cite{trans}, вопросы патентования, возникающие в связи с развитием ИИ, можно разделить на три группы:

\begin{itemize}
\item Патентование самого ИИ;
\item Патентование изобретений, использующих ИИ;
\item Патентование изобретений, созданных с использованием ИИ.
\end{itemize}

Обращаясь к проблематике патентования нейронных сетей, можно сказать,
что обычно патентуются изобретения, состоящие в совершенствовании ИИ, например
архитектура искусственной нейронной сети, способ ее обучения, способ подготовки
входных данных.

При этом автор \cite{trans} подчеркивает, что к такого рода изобретениям предъявляются
точно такие же требования, как и к любым другим: требование раскрытия сущности
изобретения, а также условия патентоспособности (новизна, изобретательский уровень
и промышленная применимость). Он также отметает положительную динамику патентования
российскими компаниями своих разработок в сфере ИИ.

Тем не менее, автор так же обращает внимание на тот факт, что современные темпы
развития технологии ставят перед патентным ведомством сложную задачу поиска баланса
интересов, с тем чтобы обеспечить надлежащую правовую защиту авторам и правообладателями,
с одной стороны, и не стать препятствием для технического развития – с другой.

Искусственный интеллект как «субъект» патентных отношений так же рассматривается в работе \cite{reg}.
Ее автор выделяет основные вопросы патентного права, на которые оказывает непосредственное влияние ИИ:

\begin{itemize}
\item патентоспособность изобретений, созданных с помощью ИИ
\item ответственность за нарушение патентных прав со стороны ИИ
\item роль искусственного интеллекта, как «субъекта» патентных отношений.
\end{itemize}

Автор отмечает, что попытки признать право ИИ на авторство может иметь самые непредсказуемые
и далеко идущие последствия не только для патентной системы, но и всего права интеллектуальной
собственности,  и что в данном контексте более целесообразным является подход, который закрепляет
права на изобретение за физическим или юридическим лицом, которые изначально способствовали созданию
самого программного обеспечения для компьютера с искусственным интеллектом. Это заключение в какой-то мере
согласуется с некоторыми из тех, что были рассмотрены в предыдущем разделе.

Ответственность за нарушение патентных прав со стороны ИИ будет рассмотрена ниже.

\newpage

\section{Риски при использовании ИИ и ответственность}
Использование искусственного интеллекта при решении важных задач влечет за собой риски неблагоприятных
последствий.

Автор работы \cite{reg} отмечает, что в большинстве юрисдикций под патентными правами понимается
предоставление автору изобретения, полезной модели или промышленного образца исключительного права,
а также права авторства. Также патентные права включают право изобретателей исключать других лиц
от практики использования запатентованных изобретений без соответствующих на то разрешений в течение
всего срока действия патента. Однако в случае нарушения данных прав со стороны искусственного
интеллекта в законе существует пробел.

Так же в статье \cite{reg} упоминается, что в настоящее время
законодательство большинства стран исходит из практики привлечения к ответственности человека, а не ИИ.
Но данный факт вызывает дискуссии, связанные с тем, что конечные пользователи, как и разработчики, как правило,
не могут предвидеть наступление нарушения патентных прав.

Однако в работе \cite{reg} отмечается, что как решение проблемы можно использовать систему страхования,
которая позволит минимизировать риски наступления неблагоприятных последствий. Так же предложено
создание специальных фондов для покрытия ущерба от действий ИИ.

В статье \cite{self} авторы выделяют несколько этапов, на каждом из которых эти риски свои.
На этапе обучения алгоритма ИИ рассматриваются следующие проблемы:

\begin{itemize}
\item Защита персональных данных. Ключевым риском в области защиты персональных данных на этапе обучения
алгоритма ИИ является возможность деанонимизации данных.
\item Проблема дискриминации: алгоритм ИИ в процессе обучения может обучиться дискриминировать, например
по признакам пола, расы, национальности, вероисповедания.
\end{itemize}

С первой проблемой связан тот факт, что разработчик алгоритма ИИ потенциально может нарушить законодательство
о персональных данных, если ИИ сможет деанонимизировать данные.

Вторая проблема влечет достаточно очевидные риски нарушения законов о дискриминации по самым различным признакам.
Но на этапе обучения алгоритма возможно снизить риск
дискриминации. В частности, разработчики из Google Brain Team предложили метод обучения алгоритма,
основанный на запрете дискриминации внутри защищенных классов.

На этапе эксплуатации правовые риски применения ИИ проявляются в иных аспектах.

\begin{itemize}
\item Ответственность за деликты. Причинение вреда жизни или здоровью в процессе эксплуатации систем ИИ.
\item Ответственность за картельные сговоры. Все чаще для достижения тайных антиконкурентных соглашений
используются цифровые технологии.
\end{itemize}

В отношении проблемы деликтов ведется много дискуссий. В частности можно ли возложить ответственность на
разработчика программы ИИ или производителя товара, работающего на основании ИИ? При каких условиях
ответственность может быть возложена на пользователя системы ИИ? В настоящее время, по
утверждению авторов \cite{self}, универсального ответа на поставленные вопросы не существует.

Ключевой проблемой для антимонопольного права применительно к цифровым картелям является то,
что цифровые картели открывают возможность сговора без участия человека, в автоматическом режиме.
Отсюда возникает вопрос: кто является субъектом ответственности за цифровые картели, т. е. за сговор
в автоматическом режиме. Можно ли считать ответственными за сговор разработчиков программы или
хозяйствующих субъектов, которые ее используют? По заявлению авторов \cite{self}, ответ на этот вопрос
так же пока что не найден.
\newpage

\section{Примеры некоторых проблем}
\subsection{В медицине}
Некоторые из рассмотренных выше проблем находят отражение в реальной жизни
уже на сегодняшний день. Например,
в работе \cite{vac} автор рассматривает проблематику использования технологий искусственного
интеллекта при создании объектов интеллектуальной собственности, в частности вакцин, в условиях
борьбы с пандемией.

Согласно  \cite{vac} академическая, техническая наука зачастую эксплуатирует экономическую теорию патентной защиты для
обоснования патентования жизненно важных лекарств и вакцин, притом что экономическая теория патентной
защиты исходит из того обстоятельства, что инновации происходят благодаря патентам на изобретения,
защищающим инвестиции в исследования и разработки, сделанные изобретателями, а отсутствие механизмов
и возможности патентной защиты как таковой приведет к ситуации, когда такие инновации в лекарствах и
вакцинах будут происходить со значительно меньшей скоростью. Проблематика получения патентной охраны
на соответствующие технические решения, приводящие к реализации вакцины как способа борьбы с распространением
вирусной инфекции, является актуальной в контексте стимулирования, окупаемости и ускорения процессов
изобретательской деятельности.

При этом одной из важнейших проблем остается достижение баланса между исключительными правами изобретателей
и общественным интересом в контексте необходимого распространения и доступности вакцин как в рамках одного
государства, так и в мировых масштабах в условиях пандемии.

Помимо этого, в ситуациях, когда системы искусственного интеллекта участвуют в процессе принятия решений,
так или иначе связанных со здоровьем человека, нет окончательной ясности, насколько было бы разумным
привлекать врачей к ответственности за вред, причиненный пациентам. Поэтому слишком важные решения
к принятию ИИ не допускаются.

Относительно персональной ответственности за действия искусственного интеллекта существует справедливая
на данном этапе технологического развития концепция ответственности лиц, причастных к разработке,
программированию, эксплуатации искусственного интеллекта и управлению им.

\subsection{В учреждениях МВД}
Другой проблемной сферой в гражданско-правовом отношении является использование ИИ в казённых
учреждениях МВД России \cite{civil}.

К числу служебных результатов интеллектуальной деятельности, создаваемых в системе МВД России,
относятся также объекты в сфере патентного права – служебные изобретения, служебные полезные модели
и служебные промышленные образцы. Для создания служебных изобретений в настоящее время также активно
используются технологии с искусственным интеллектом.

Искусственный интеллект не только выступает в
качестве сложного инструмента, управляемого сотрудником (работником), но и нередко автономно
осуществляет деятельность, которую можно отнести к изобретательской. Однако в настоящее время
не существует достаточной нормативной базы, регулирующей создание и использование
результатов деятельности искусственного интеллекта.

По мнению автора \cite{civil},
законодательством должен быть обеспечен баланс между стимулом для программиста (сотрудника / работника)
по созданию соответствующих программ для искусственного интеллекта в казённых учреждениях МВД России
и преимуществами, которые они смогут извлечь из возможности свободно
использовать конечный результат соответствующей деятельности искусственного интеллекта.

\subsection{Особенности правового режима за рубежом}
Правовые проблемы, связанные с использованием ИИ, касаются не только России. За рубежом они
актуальны в такой же мере.

Согласно статье \cite{abr}, в \textbf{Великобритании} закон не содержит  положения о возможности создания
компьютером объектов патентного права. Кроме того, те нормы закона, которые допускают создание компьютером
произведений, касаются лишь ограниченного круга произведений. Вопрос о возможности применения к созданным
ИИ результатам критериев оригинальности остается нерешенным.

В \textbf{США} регистрация в качестве объектов авторского права продуктов деятельности
искусственного интеллекта, созданных без какого-либо творческого вклада и вмешательства человека, не
допускается. Судебная же практика относительно того, кому принадлежат права на объекты интеллектуальной
собственности, полученные ИИ, отсутствует.

В той же статье \cite{abr} также упоминается, что право интеллектуальной собственности в \textbf{Канаде}
не содержит специального регулирования в отношении объектов, созданных с использованием технологий
ИИ. Авторское право распространяется только на оригинальные произведения, которые должны быть
продуктом навыков и видения автора. Получение результатов обязательно требует приложения интеллектуальных
усилий.

В \textbf{Японии} в данный момент идет разработка нового законодательства, согласно которому правообладателя
того или иного результата предлагается определять индивидуально в каждом конкретном случае и с учетом
обстоятельств дела. Такая концепция нового регулирования учитывает не только возможность защиты
продуктов деятельности ИИ авторским правом, но и потенциал применения к ним норм патентного права.

\newpage

\section{Заключение}
Подводя итоги, можно заключить, что когда поднимается тема права интеллектуальной собственности
в контексте искусственного интеллекта, два главных вопроса , на которые стоит обратить внимание,
это правосубъектность ИИ и проблема патентной охраны результатов его деятельности.

Из рассмотренных в данной работе статей видно, что единого решения ни по одному ни по другому вопросу нет,
но проблеме уделяется пристальное внимание со стороны законодателей и ученых. Если же выделять аспекты, в
которых сходятся большинство из них, то следует сказать, что большая часть выступает за то, что
следует оценивать интеллектуальный вклад человека в продукт деятельности ИИ, а ответственность за действия ИИ
зависит от конкретных обстоятельств.

Так же проиллюстрированы проблемы, уже имевшие место в реальной жизни. На их основании следует сделать
соответствующие выводы о том, в каких местах действующего закона есть неточности и пробелы и устранить их.
\newpage

\begin{thebibliography}{}
% ! AUTO
\bibitem{II}
Оморов Р. О., Интеллектуальная собственность и искусственный интеллект. // Технологии искусственного
интеллекта в менеджменте., 2020
% ! AUTO
\bibitem{chel}
Ю. О. Коряченкова, Искусственный интеллект: вызовы для права интеллектуальной
собственности, 2022

% ! AUTO
\bibitem{probs}
Сергеев А. В., Проблемы правовой охраны искусственного интеллекта в области
интеллектуальной собственности // Современная наука: актуальные проблемы
теории и практики, 2021. - С. 135-137

% ! AUTO
\bibitem{mor}
П.М. Морхат, Особенности развития права интеллектуальной собственности в
контексте использования искусственного интеллекта, 2020

% ! AUTO
\bibitem{trans}
Коданева С.И., Трансформация интеллектуальной собственности под влиянием развития искусственного интеллекта.
(Обзор) // Социальные новации и социальные науки. – Москва : ИНИОН РАН, 2021. – № 2. – С. 132–141.

% ! AUTO
\bibitem{reg}
Купчина Е. В., Искусственный интеллект и интеллектуальная собственность: вопросы правового регулирования патентных отношений
// Legal Concept = Правовая парадигма. – 2020. – Т. 19, № 4. С. 48–54.

% ! AUTO
\bibitem{self}
Е. А. Войниканис, Е. В. Семенова, Г. С. Тюляев, Искусственный интеллект и право: вызовы и возможности
самообучающихся алгоритмов. // Вестник ВГУ. Серия: Право, 2018

% ! AUTO
\bibitem{vac}
Шахназаров Б. А. Применение технологий искусственного интеллекта при создании вакцин и иных объектов интеллектуальной
собственности (правовые аспекты) // Актуальные проблемы российского права. — 2020. — Т. 15. — № 7. — С. 76—90

% ! AUTO
\bibitem{civil}
А.А. Молчанов, Гражданско-правовые проблемы использования искусственного интеллекта в казённых учреждениях
системы МВД России в контексте права интеллектуальной собственности. // Вестник Санкт-Петербургского университета
МВД России, 2018. -№ 4 - C. 80

% ! AUTO
\bibitem{abr}
Ролинсон П., Ариевич Е.А., Ермолина Д.Е., Объекты интеллектуальной собственности, создаваемые с помощью
искусственного интеллекта: особенности правового режима в России и за рубежом, 2018

\end{thebibliography}


\end{document}
