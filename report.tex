\include{preamble}

\newtotcounter{citenum} %From the package documentation
\def\oldbibitem{}
\let\oldbibitem=\bibitem
\def\bibitem{\stepcounter{citenum}\oldbibitem}

\begin{document}
\includepdf[pages={1}]
{title.pdf}

\tableofcontents
\newpage

\section{Введение}
Один из наиболее распространенных движущих факторов прогресса – искусственный
интеллект (далее – ИИ). ИИ следует рассматривать как программу, которая, благодаря
итеративному обучению на больших массивах данных, способна создавать независимые от
замысла разработчиков результаты.

Крайне широкий спектр его применения требует принятия
своевременных и эффективных мер по совершенствованию правового регулирования по
обширному кругу вопросов. Наиболее актуальные темы включают вопросы безопасности,
ответственности, использования и защиты данных, интеллектуальной собственности.

Цель данной работы -- обозначить общие правовые проблемы, возникающие при использовании ИИ,
ответственность, связанную с рисками применения самообучающихся алгоритмов для
решения различных задач, и привести примеры, иллюстрирующие эти задачи в реальной жизни.

\newpage
\section{Правосубъектность искусственного интеллекта}
Одной из главных мировых проблем является правосубъектность ИИ. Ключевые вопросы, связанные
с этой темой изложены в статье \cite{II}. Её автор также дает ответ на некоторые из них.
В частности, по теме авторства и права собственности он выделяет следующие решения:

\begin{enumerate}
\item На оригинальные литературные и художественные произведения, которые создаются ИИ в автономном режиме,
следует распространить режим авторско-правовой охраны.
\item Права авторства следует предоставить человеку (коллективу) – разработчику ИИ с фиксацией последнего как
субсубъекта или инструмента субъекта права.
\item Возможно, следует ввести определенные ограничения правовой охраны для оригинальных литературных и художественных произведений.
\end{enumerate}




Согласно \cite{chel},
проявление творческого потенциала ИИ не обеспечивает его включение как субъекта в рамки
права интеллектуальной собственности, основополагающие концепции которого в качестве автора,
способного к творческой деятельности, рассматривают исключительно физическое лицо. В статье
\cite{chel} данный вопрос, при взятых во внимание некоторых международных конференциях,
признается дискуссионным. Но в качестве наиболее вероятных решений проблемы приняты следующие положения:

\begin{enumerate}
\item Отказ от рассмотрения ИИ в качестве самостоятельного субъекта права интеллектуальной собственности.
\item Проведение разграничения результатов деятельности ИИ по критерию степени участия человека и
использования ИИ, а также установление различных правовых режимов для случаев, где ИИ играет
инструментальную роль, и случаев, где ИИ выступает с определенной степенью автономности.
\item Включение в национальное законодательство нормы о возможности использования законно
доступных объектов интеллектуальной собственности для целей обучения систем ИИ, если
правообладателем не выражено явное возражение против этого в надлежащей форме.
\end{enumerate}

В статье \cite{probs} автор придерживается аналогичного мнения. Он считает
обоснованным подход, в котором автором и правообладателем, соответственно,
будет признаваться владелец (собственник) робота. Неминуемо встаёт вопрос о том,
а каков будет правовой статус искусственного интеллекта после смерти его владельца?
Кто будет нести ответственность за все то, что успеет совершить ИИ? Автор считает, что
искусственный интеллект не может нести ответственность сам по себе, поскольку его действия
или бездействия зависят от оператора (владельца). Но этот вопрос открыт для обсуждения. И в
случае сильно развитого ИИ, законодатель обязан пересмотреть пределы ответственности самого
интеллекта, его оператора или создателя.

Однако существует и несколько иной вариант решения проблемы правосубъектности ИИ. В работе
\cite{mor} автор предлагает следующую альтернативу: наделение системы искусственного интеллекта
правовым статусом социального агента, не имеющего собственных прав; таким образом, все произведения,
создаваемые с участием такой системы, переходят в общественное достояние. Если развить эту идею, то
нет насущной необходимости кардинально менять всю систему и принципы данной отрасли права для того,
чтобы обеспечить признание правосубъектности систем искусственного интеллекта. Тем временем машины
не будут настолько обособлены от людей, как это предполагается в статьях \cite{chel} и \cite{probs}.


\newpage

\section{Проблема патентной охраны}
Согласно \cite{trans}, вопросы патентования, возникающие в связи с развитием ИИ, можно разделить на три группы:

\begin{itemize}
\item Патентование самого ИИ;
\item Патентование изобретений, использующих ИИ;
\item Патентование изобретений, созданных с использованием ИИ.
\end{itemize}

Обращаясь к проблематике патентования нейронных сетей, можно сказать,
что обычно патентуются изобретения, состоящие в совершенствовании ИИ, например
архитектура искусственной нейронной сети, способ ее обучения, способ подготовки
входных данных.

При этом автор \cite{trans} подчеркивает, что к такого рода изобретениям предъявляются
точно такие же требования, как и к любым другим: требование раскрытия сущности
изобретения, а также условия патентоспособности (новизна, изобретательский уровень
и промышленная применимость). Он также отметает положительную динамику патентования
российскими компаниями своих разработок в сфере ИИ.
\newpage

\section{Риски при использовании ИИ и ответственность}
Использование искусственного интеллекта при решении важных задач влечет за собой риски неблагоприятных
последствий. В статье \cite{self} авторы выделяют несколько этапов, на каждом из которых эти риски свои.
На этапе обучения алгоритма ИИ рассматриваются следующие проблемы:

\begin{itemize}
\item Защита персональных данных. Ключевым риском в области защиты персональных данных на этапе обучения
алгоритма ИИ является возможность деанонимизации данных.
\item Проблема дискриминации: алгоритм ИИ в процессе обучения может обучиться дискриминировать, например
по признакам пола, расы, национальности, вероисповедания.
\end{itemize}

С первой проблемой связан тот факт, что разработчик алгоритма ИИ потенциально может нарушить законодательство
о персональных данных, если ИИ сможет деанонимизировать данные.

Вторая проблема влечет достаточно очевидные риски нарушения законов о дискриминации по самым разлиным признакам.
Но на этапе обучения алгоритма возможно снизить риск
дискриминации. В частности, разработчики из Google Brain Team предложили метод обучения алгоритма,
основанный на запрете дискриминации внутри защищенных классов.

На этапе эксплуатации правовые риски применения ИИ проявляются в иных аспектах.

\begin{itemize}
\item Ответственность за деликты. Причинение вреда жизни или здоровью в процессе эксплуатации систем ИИ.
\item Ответственность за картельные сговоры. Все чаще для достижения тайных антиконкурентных соглашений
используются цифровые технологии.
\end{itemize}

В отношении проблемы деликтов ведется много дискуссий. В частности можно ли возложить ответственность на
разработчика программы ИИ или производителя товара, работающего на основании ИИ? При каких условиях
ответственность может быть возложена на пользователя системы ИИ? В настоящее время, по
утверждению авторов \cite{self}, универсального ответа на поставленные вопросы не существует.

Ключевой проблемой для антимонопольного права применительно к цифровым картелям является то,
что цифровые картели открывают возможность сговора без участия человека, в автоматическом режиме.
Отсюда возникает вопрос: кто является субъектом ответственности за цифровые картели, т. е. за сговор
в автоматическом режиме. Можно ли считать ответственными за сговор разработчиков программы или
хозяйствующих субъектов, которые ее используют? По заявлению авторов \cite{self}, ответ на этот вопрос
так же пока что не найден.
\newpage

\section{Примеры некоторых проблем}
\subsection{В медицине}
Некоторые из рассмотренных выше проблем находят отражение уже на сегодняшний день. Например,
в работе \cite{vac} автор рассматривает проблематику использования технологий искусственного
интеллекта при создании объектов интеллектуальной собственности, в частности вакцин, в условиях
борьбы с пандемией.

Согласно  \cite{vac} академическая, техническая наука зачастую эксплуатирует экономическую теорию патентной защиты для
обоснования патентования жизненно важных лекарств и вакцин, притом что экономическая теория патентной
защиты исходит из того обстоятельства, что инновации происходят благодаря патентам на изобретения,
защищающим инвестиции в исследования и разработки, сделанные изобретателями, а отсутствие механизмов
и возможности патентной защиты как таковой приведет к ситуации, когда такие инновации в лекарствах и
вакцинах будут происходить со значительно меньшей скоростью. Проблематика получения патентной охраны
на соответствующие технические решения, приводящие к реализации вакцины как способа борьбы с распространением
вирусной инфекции, является актуальной в контексте стимулирования, окупаемости и ускорения процессов
изобретательской деятельности.

При этом одной из важнейших проблем остается достижение баланса между исключительными правами изобретателей
и общественным интересом в контексте необходимого распространения и доступности вакцин как в рамках одного
государства, так и в мировых масштабах в условиях пандемии.

Помимо этого, в ситуациях, когда системы искусственного интеллекта участвуют в процессе принятия решений,
так или иначе связанных со здоровьем человека, нет окончательной ясности, насколько было бы разумным
привлекать врачей к ответственности за вред, причиненный пациентам. Поэтому слишком важные решения
к принятию ИИ не допускаются.

Относительно персональной ответственности за действия искусственного интеллекта существует справедливая
на данном этапе технологического развития концепция ответственности лиц, причастных к разработке,
программированию, эксплуатации искусственного интеллекта и управлению им.

\subsection{В учреждениях МВД}
Другой проблемной сферой в гражданско-правовом отношении является использование ИИ в казённых
учреждениях МВД России \cite{civil}.

К числу служебных результатов интеллектуальной деятельности, создаваемых в системе МВД России,
относятся также объекты в сфере патентного права – служебные изобретения, служебные полезные модели
и служебные промышленные образцы. Для создания служебных изобретений в настоящее время также активно
используются технологии с искусственным интеллектом.

Искусственный интеллект не только выступает в
качестве сложного инструмента, управляемого сотрудником (работником), но и нередко автономно
осуществляет деятельность, которую можно отнести к изобретательской. Однако в настоящее время
не существует достаточной нормативной базы, регулирующей создание и использование
результатов деятельности искусственного интеллекта.

По мнению автора \cite{civil},
законодательством должен быть обеспечен баланс между стимулом для программиста (сотрудника / работника)
по созданию соответствующих программ для искусственного интеллекта в казённых учреждениях МВД России
и преимуществами, которые они смогут извлечь из возможности свободно
использовать конечный результат соответствующей деятельности искусственного интеллекта.
\newpage

\section{Заключение}
% Бурное развитие компьютерной техники и систем программирования привели к возникновению технологий и
% систем искусственного интеллекта, которые могут функционировать в автономном режиме. Такие технологии
% и системы могут создавать объекты интеллектуальной собственности. Соответственно, возникают проблемные
% вопросы о правосубъектности искусственного интеллекта по отношению к интеллектуальной собственности.
% Многие правовые вопросы требуют решения на международном уровне под эгидой Всемирной организации интеллектуальной
% собственности.
\newpage

\begin{thebibliography}{}
\bibitem{II}
Оморов Р. О., Интеллектуальная собственность и искусственный интеллект. // Технологии искусственного
интеллекта в менеджменте., 2020
% ! AUTO
\bibitem{chel}
Ю. О. Коряченкова, Искусственный интеллект: вызовы для права интеллектуальной
собственности, 2022

% ! AUTO
\bibitem{probs}
Сергеев А. В., Проблемы правовой охраны искусственного интеллекта в области
интеллектуальной собственности // Современная наука: актуальные проблемы
теории и практики, 2021. - С. 135-137

% ! AUTO
\bibitem{mor}
П.М. Морхат, Особенности развития права интеллектуальной собственности в
контексте использования искусственного интеллекта, 2020

% ! AUTO
\bibitem{trans}
Коданева С.И., Трансформация интеллектуальной собственности под влиянием развития искусственного интеллекта.
(Обзор) // Социальные новации и социальные науки. – Москва : ИНИОН РАН, 2021. – № 2. – С. 132–141.

% ! AUTO
\bibitem{self}
Е. А. Войниканис, Е. В. Семенова, Г. С. Тюляев, Искусственный интеллект и право: вызовы и возможности
самообучающихся алгоритмов. // Вестник ВГУ. Серия: Право, 2018

% ! AUTO
\bibitem{vac}
Шахназаров Б. А. Применение технологий искусственного интеллекта при создании вакцин и иных объектов интеллектуальной
собственности (правовые аспекты) // Актуальные проблемы российского права. — 2020. — Т. 15. — № 7. — С. 76—90

% ! AUTO
\bibitem{civil}
А.А. Молчанов, Гражданско-правовые проблемы использования искусственного интеллекта в казённых учреждениях
системы МВД России в контексте права интеллектуальной собственности. // Вестник Санкт-Петербургского университета
МВД России, 2018. -№ 4 - C. 80

\bibitem{abr}
Ролинсон П., Ариевич Е.А., Ермолина Д.Е., Объекты интеллектуальной собственности, создаваемые с помощью
искусственного интеллекта: особенности правового режима в России и за рубежом, 2018

\bibitem{reg}
Купчина Е. В., Искусственный интеллект и интеллектуальная собственность: вопросы правового регулирования патентных отношений
// Legal Concept = Правовая парадигма. – 2020. – Т. 19, № 4. С. 48–54.

\end{thebibliography}



\end{document}
